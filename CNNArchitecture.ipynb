{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Architecture | Assignment"
      ],
      "metadata": {
        "id": "q6NSgwbkqNN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is the role of filters and feature maps in Convolutional Neural\n",
        "Network (CNN)?"
      ],
      "metadata": {
        "id": "2qQUNX5tqdkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - In a CNN, filters (or kernels) are small matrices that slide over the input image to detect specific patterns like edges, textures, or shapes. Each filter â€œlooks forâ€ a particular feature.\n",
        "\n",
        "When a filter is applied to the image, it produces a feature map, which shows where that feature is present in the image. Feature maps are important because they allow the CNN to learn hierarchical representations, capturing simple patterns in early layers and more complex patterns in deeper layers, which helps in tasks like image classification."
      ],
      "metadata": {
        "id": "5pGRtfNjucTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of padding and stride in CNNs(Convolutional Neural\n",
        "Network). How do they affect the output dimensions of feature maps?\n"
      ],
      "metadata": {
        "id": "U_KoBdcgqgm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - In CNNs, **padding** and **stride** control how the convolution operation is applied to an image.\n",
        "\n",
        "**Padding** means adding extra pixels (usually zeros) around the border of the input image. It is used to control the size of the output feature map. With padding, the spatial size can be preserved (*same padding*), while without padding (*valid padding*), the output size becomes smaller.\n",
        "\n",
        "**Stride** is the number of pixels the filter moves at each step. A **larger stride** reduces the output feature map size because the filter skips more pixels, while a **smaller stride** produces a larger output.\n",
        "\n",
        "**Effect on output size:**\n",
        "\n",
        "* Increasing padding â†’ larger or same output size\n",
        "* Increasing stride â†’ smaller output size\n",
        "\n",
        "Thus, padding helps retain spatial information, and stride helps control downsampling and computation.\n"
      ],
      "metadata": {
        "id": "iEj3n3QguSBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Define receptive field in the context of CNNs. Why is it important for deep\n",
        "architectures?"
      ],
      "metadata": {
        "id": "3_JpIX3Jqjfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - In CNNs, the receptive field is the region of the input image that influences the activation of a particular neuron in a feature map. In other words, it shows how much of the original image a neuron can â€œsee.â€\n",
        "\n",
        "The receptive field is important for deep architectures because, as more convolution and pooling layers are stacked, the receptive field increases. This allows the network to capture local features (like edges) in early layers and global features (like shapes and objects) in deeper layers, improving overall image understanding and classification performance."
      ],
      "metadata": {
        "id": "PllYxcw2uIPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Discuss how filter size and stride influence the number of parameters in a\n",
        "CNN."
      ],
      "metadata": {
        "id": "ehBMNVsnqmDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - In a CNN, the filter size and stride directly affect the number of parameters and feature maps. A larger filter size (for example 5Ã—5 instead of 3Ã—3) increases the number of parameters because more weights are needed in each filter. Smaller filters require fewer parameters and are more efficient.\n",
        "\n",
        "The stride controls how the filter moves over the image. A larger stride reduces the size of the output feature map, which lowers computation but does not change the number of parameters in the filter itself. A smaller stride produces larger feature maps, increasing computation but keeping the same number of parameters.\n",
        "\n",
        "In summary, filter size affects the number of parameters, while stride mainly affects the output size and computation cost."
      ],
      "metadata": {
        "id": "5EI4Plmxt_25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Compare and contrast different CNN-based architectures like LeNet,\n",
        "AlexNet, and VGG in terms of depth, filter sizes, and performance"
      ],
      "metadata": {
        "id": "iUeu0Kz6qo1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - LeNet, AlexNet, and VGG are different CNN architectures with increasing complexity. LeNet is a shallow network with fewer layers and larger filters (5Ã—5), mainly used for simple tasks like digit recognition. AlexNet is deeper and uses larger filters such as 11Ã—11 and 5Ã—5, giving better performance on complex images. VGG is very deep and uses small 3Ã—3 filters, which helps in learning detailed features and gives higher accuracy, but it requires more computation and memory."
      ],
      "metadata": {
        "id": "uT6C1Zpgt38L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Using keras, build and train a simple CNN model on the MNIST dataset\n",
        "from scratch. Include code for module creation, compilation, training, and evaluation"
      ],
      "metadata": {
        "id": "xXC9chnYqr27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate model\n",
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "Y5OQ6BUXtgbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Load and preprocess the CIFAR-10 dataset using Keras, and create a\n",
        "CNN model to classify RGB images. Show your preprocessing and architecture."
      ],
      "metadata": {
        "id": "xwdUOljTquzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
        "\n",
        "# Evaluate model\n",
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "m2gbNnc7tYB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Using PyTorch, write a script to define and train a CNN on the MNIST\n",
        "dataset. Include model definition, data loaders, training loop, and accuracy evaluation."
      ],
      "metadata": {
        "id": "KRL45OfBqyE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=True, transform=transform, download=True\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=False, transform=transform, download=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# CNN Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "D1D8jYSIs__-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Given a custom image dataset stored in a local directory, write code using\n",
        "Keras ImageDataGenerator to preprocess and train a CNN model.\n"
      ],
      "metadata": {
        "id": "W0rG5cbGq1ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Image preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    \"dataset/train\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    \"dataset/validation\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_data, epochs=5, validation_data=val_data)\n"
      ],
      "metadata": {
        "id": "mSZqgq7ds30p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You are working on a web application for a medical imaging startup. Your\n",
        "task is to build and deploy a CNN model that classifies chest X-ray images into â€œNormalâ€\n",
        "and â€œPneumoniaâ€ categories. Describe your end-to-end approachâ€“from data preparation\n",
        "and model training to deploying the model as a web app using Streamlit.\n"
      ],
      "metadata": {
        "id": "4KvRcwYmq65n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - To solve the problem of classifying chest X-ray images into **Normal** and **Pneumonia** categories, an end-to-end deep learning pipeline is designed that covers **data preparation, model training, evaluation, and deployment** as a web application using **Streamlit**.\n",
        "\n",
        "\n",
        "## **1. Data Preparation**\n",
        "\n",
        "The first step involves collecting a labeled **Chest X-ray image dataset** containing two classes: *Normal* and *Pneumonia*. The dataset is divided into **training, validation, and testing sets** to ensure unbiased model evaluation.\n",
        "\n",
        "All images are preprocessed by:\n",
        "\n",
        "* Resizing them to a fixed dimension (224 Ã— 224 pixels)\n",
        "* Normalizing pixel values to the range [0,1]\n",
        "* Converting grayscale images to RGB format if required\n",
        "\n",
        "To improve model generalization and reduce overfitting, **data augmentation** techniques such as rotation, zooming, and horizontal flipping are applied to the training data.\n",
        "\n",
        "\n",
        "\n",
        "## **2. Model Building**\n",
        "\n",
        "A **Convolutional Neural Network (CNN)** is used for image classification. Instead of training a model from scratch, **transfer learning** is employed using a pre-trained network such as **ResNet50 or VGG16**, which has already learned rich image features.\n",
        "\n",
        "The CNN architecture consists of:\n",
        "\n",
        "* A pre-trained convolutional base\n",
        "* Global Average Pooling layer\n",
        "* Fully connected dense layers\n",
        "* Dropout layer to prevent overfitting\n",
        "* Final output layer with a **sigmoid activation function** for binary classification\n",
        "\n",
        "\n",
        "\n",
        "## **3. Model Training**\n",
        "\n",
        "The model is compiled using:\n",
        "\n",
        "* **Binary Cross-Entropy** loss function\n",
        "* **Adam optimizer**\n",
        "* **Accuracy** as the evaluation metric\n",
        "\n",
        "Training is performed on the training dataset while monitoring performance on the validation dataset. Techniques such as **early stopping** and **model checkpointing** are used to save the best performing model and avoid overfitting.\n",
        "\n",
        "\n",
        "\n",
        "## **4. Model Evaluation**\n",
        "\n",
        "The trained model is evaluated on the test dataset using:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* Confusion Matrix\n",
        "\n",
        "In medical diagnosis tasks, **recall is particularly important** to minimize false negatives, ensuring pneumonia cases are not missed.\n",
        "\n",
        "\n",
        "\n",
        "## **5. Model Saving**\n",
        "\n",
        "After successful training and evaluation, the model is saved in `.h5` format so it can be reused during deployment without retraining.\n",
        "\n",
        "\n",
        "## **6. Deployment Using Streamlit**\n",
        "\n",
        "The trained CNN model is deployed as a **web application using Streamlit**, which provides a simple and interactive user interface.\n",
        "\n",
        "The Streamlit app allows users to:\n",
        "\n",
        "* Upload a chest X-ray image\n",
        "* View the uploaded image\n",
        "* Automatically preprocess the image\n",
        "* Get real-time predictions (Normal or Pneumonia)\n",
        "* Display prediction confidence scores\n",
        "\n",
        "A medical disclaimer is added to clarify that the system is intended for **educational and clinical assistance purposes only**, not for final medical diagnosis.\n",
        "\n",
        "\n",
        "## **7. Final Outcome**\n",
        "\n",
        "The deployed application successfully performs real-time classification of chest X-ray images and provides an easy-to-use interface for users. This end-to-end solution demonstrates the practical application of **deep learning in medical imaging**, combining model development with real-world deployment.\n",
        "\n",
        "\n",
        "###  **Conclusion**\n",
        "\n",
        "This project showcases a complete machine learning workflowâ€”from data preprocessing and CNN training to deploying a production-ready web applicationâ€”making it suitable for real-world medical imaging use cases.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4wLg4aNMsOBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Chest X-Ray Pneumonia Detection\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "\n",
        "# Load trained model\n",
        "@st.cache_resource\n",
        "def load_cnn_model():\n",
        "    return load_model(\"model.h5\")\n",
        "\n",
        "model = load_cnn_model()\n",
        "\n",
        "# App title\n",
        "st.title(\"ðŸ©º Chest X-Ray Pneumonia Detection\")\n",
        "st.write(\"Upload a chest X-ray image to classify it as **Normal** or **Pneumonia**.\")\n",
        "\n",
        "# Image preprocessing function\n",
        "def preprocess_image(image):\n",
        "    image = image.resize((224, 224))\n",
        "    image = image.convert(\"RGB\")\n",
        "    image = np.array(image) / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return image\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\n",
        "    \"Upload Chest X-Ray Image\",\n",
        "    type=[\"jpg\", \"jpeg\", \"png\"]\n",
        ")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption=\"Uploaded X-Ray Image\", use_column_width=True)\n",
        "\n",
        "    # Predict button\n",
        "    if st.button(\"Predict\"):\n",
        "        with st.spinner(\"Analyzing X-ray...\"):\n",
        "            processed_image = preprocess_image(image)\n",
        "            prediction = model.predict(processed_image)[0][0]\n",
        "\n",
        "        # Prediction result\n",
        "        if prediction > 0.5:\n",
        "            st.error(f\" Pneumonia Detected (Confidence: {prediction:.2f})\")\n",
        "        else:\n",
        "            st.success(f\" Normal Chest X-Ray (Confidence: {1 - prediction:.2f})\")\n",
        "\n",
        "# Disclaimer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"This tool is for educational purposes only and should not replace professional medical diagnosis.\")\n"
      ],
      "metadata": {
        "id": "qPPTncALrwf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLjIQqHAqMFR"
      },
      "outputs": [],
      "source": []
    }
  ]
}