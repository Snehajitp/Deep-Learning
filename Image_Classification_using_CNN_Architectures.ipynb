{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification using CNN Architectures"
      ],
      "metadata": {
        "id": "OmZBmXNQfy0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Convolutional Neural Network (CNN), and how does it differ from\n",
        "traditional fully connected neural networks in terms of architecture and performance on\n",
        "image data?"
      ],
      "metadata": {
        "id": "suSfKsWrf4Kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer :**\n",
        "\n",
        "A **Convolutional Neural Network (CNN)** is a type of deep learning model mainly used for **image and visual data processing**. It automatically learns spatial features such as edges, textures, and shapes from images using convolution operations.\n",
        "\n",
        "**Difference from Fully Connected Neural Networks:**\n",
        "\n",
        "* CNNs use **convolutional layers and pooling layers**, whereas traditional neural networks use only fully connected layers.\n",
        "* CNNs have **fewer parameters** due to weight sharing and local connections, making them more efficient.\n",
        "* CNNs preserve the **spatial structure** of images, while fully connected networks flatten images and lose spatial information.\n",
        "* CNNs perform **better on image data** by learning hierarchical features and reducing overfitting.\n",
        "\n",
        "**Conclusion:**\n",
        "CNNs are specifically designed for image data and significantly outperform traditional fully connected networks in computer vision tasks.\n"
      ],
      "metadata": {
        "id": "H-5f3gbliiBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Discuss the architecture of LeNet-5 and explain how it laid the foundation\n",
        "for modern deep learning models in computer vision. Include references to its original\n",
        "research paper."
      ],
      "metadata": {
        "id": "-SkLpsJXf6R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer :**\n",
        "\n",
        "LeNet-5 is one of the earliest convolutional neural network (CNN) architectures, proposed by **Yann LeCun et al.** in 1998 for handwritten digit recognition. It was designed to classify images such as digits from the MNIST dataset.\n",
        "\n",
        "**Architecture of LeNet-5:**\n",
        "LeNet-5 consists of alternating **convolutional layers and pooling layers**, followed by fully connected layers. The network starts with a convolution layer that extracts basic features, followed by average pooling to reduce spatial dimensions. This pattern is repeated, and the final layers are fully connected to perform classification.\n",
        "\n",
        "**Foundation for Modern Deep Learning:**\n",
        "LeNet-5 introduced key concepts such as **local receptive fields**, **shared weights**, and **subsampling (pooling)**, which are fundamental to modern CNNs. It demonstrated that convolutional architectures can effectively learn spatial hierarchies in images. Modern deep learning models build on these ideas by using deeper networks, better activation functions, and improved optimization techniques.\n",
        "\n",
        "**Reference:**\n",
        "LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). *Gradient-based learning applied to document recognition*. Proceedings of the IEEE.\n"
      ],
      "metadata": {
        "id": "3Y0BC9h5iWRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Compare and contrast AlexNet and VGGNet in terms of design principles,\n",
        "number of parameters, and performance. Highlight key innovations and limitations of\n",
        "each.\n"
      ],
      "metadata": {
        "id": "q2LS4V1Nf8Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**AlexNet** and **VGGNet** are both influential CNN architectures, but they differ in design and complexity.\n",
        "\n",
        "**Design Principles:**\n",
        "AlexNet uses **larger convolution filters** (such as 11×11 and 5×5) and introduced key ideas like **ReLU activation**, **dropout**, and **data augmentation**.\n",
        "VGGNet follows a **simpler and deeper design**, using only **small 3×3 convolution filters** stacked together to increase depth.\n",
        "\n",
        "**Number of Parameters:**\n",
        "AlexNet has about **60 million parameters**, while VGGNet has significantly more (around **138 million parameters** in VGG-16), making VGGNet more memory-intensive.\n",
        "\n",
        "**Performance:**\n",
        "VGGNet generally achieves **higher accuracy** than AlexNet due to its greater depth and uniform architecture. However, it requires more computation and memory.\n",
        "\n",
        "**Key Innovations and Limitations:**\n",
        "AlexNet’s innovation lies in making deep CNNs practical, but it is relatively shallow by today’s standards.\n",
        "VGGNet improves feature learning through depth but is limited by its **high computational cost and large model size**.\n"
      ],
      "metadata": {
        "id": "D97yh2SQiNJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is transfer learning in the context of image classification? Explain\n",
        "how it helps in reducing computational costs and improving model performance with\n",
        "limited data."
      ],
      "metadata": {
        "id": "z_swu-_Ff96Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer :**\n",
        "Transfer learning in image classification is a technique where a **pre-trained model** (trained on a large dataset like ImageNet) is reused for a new but related task. Instead of training a model from scratch, the learned features are transferred to the new problem.\n",
        "\n",
        "It reduces **computational cost** because most layers are already trained and do not need extensive retraining. It also **improves performance with limited data** by using previously learned features such as edges, textures, and shapes, which helps prevent overfitting and speeds up training.\n"
      ],
      "metadata": {
        "id": "N5hth8c8iEs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Describe the role of residual connections in ResNet architecture. How do\n",
        "they address the vanishing gradient problem in deep CNNs?"
      ],
      "metadata": {
        "id": "5ypwPqg2gAV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "Residual connections in ResNet add **shortcut paths** that directly pass the input of a layer to its output. Instead of learning a full mapping, the network learns a **residual function** (H(x) = F(x) + x).\n",
        "\n",
        "These connections help solve the **vanishing gradient problem** by allowing gradients to flow directly through the network during backpropagation. As a result, very deep CNNs can be trained efficiently without performance degradation.\n"
      ],
      "metadata": {
        "id": "sk1adTZWh7kN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Implement the LeNet-5 architectures using Tensorflow or PyTorch to\n",
        "classify the MNIST dataset. Report the accuracy and training time.\n"
      ],
      "metadata": {
        "id": "Cbf4tE0GgC-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1,28,28,1)/255.0\n",
        "X_test = X_test.reshape(-1,28,28,1)/255.0\n",
        "\n",
        "# LeNet-5 Model\n",
        "model = Sequential([\n",
        "    Conv2D(6, (5,5), activation='tanh', input_shape=(28,28,1)),\n",
        "    AveragePooling2D(),\n",
        "    Conv2D(16, (5,5), activation='tanh'),\n",
        "    AveragePooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='tanh'),\n",
        "    Dense(84, activation='tanh'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "7_KY7PDjhtve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Use a pre-trained VGG16 model (via transfer learning) on a small custom\n",
        "dataset (e.g., flowers or animals). Replace the top layers and fine-tune the model.\n",
        "Include your code and result discussion.\n"
      ],
      "metadata": {
        "id": "Lir0zIKfgEyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data loading\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train = datagen.flow_from_directory(\n",
        "    \"dataset\", target_size=(224,224),\n",
        "    class_mode=\"categorical\", subset=\"training\")\n",
        "\n",
        "val = datagen.flow_from_directory(\n",
        "    \"dataset\", target_size=(224,224),\n",
        "    class_mode=\"categorical\", subset=\"validation\")\n",
        "\n",
        "# Load VGG16\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Custom classifier\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(train.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(base_model.input, output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(train, validation_data=val, epochs=5)\n",
        "\n",
        "# Fine-tuning\n",
        "base_model.trainable = True\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train, validation_data=val, epochs=3)\n"
      ],
      "metadata": {
        "id": "pEcvyZt-hmVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a program to visualize the filters and feature maps of the first\n",
        "convolutional layer of AlexNet on an example input image.\n"
      ],
      "metadata": {
        "id": "YhCbUwRogG0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Conv2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# AlexNet-style first conv layer\n",
        "inputs = Input(shape=(224,224,3))\n",
        "conv1 = Conv2D(96, (11,11), strides=4, activation='relu')(inputs)\n",
        "model = Model(inputs, conv1)\n",
        "\n",
        "# Load and preprocess image\n",
        "img = image.load_img(\"sample.jpg\", target_size=(224,224))\n",
        "img = image.img_to_array(img) / 255.0\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Get feature maps\n",
        "feature_maps = model.predict(img)\n",
        "\n",
        "# Plot feature maps\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(feature_maps[0,:,:,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zOUhDm7Hha7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters, bias = model.layers[1].get_weights()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(6):\n",
        "    f = filters[:,:,:,i]\n",
        "    f = (f - f.min()) / (f.max() - f.min())\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(f)\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xTMrgUl4hcul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Train a GoogLeNet (Inception v1) or its variant using a standard dataset\n",
        "like CIFAR-10. Plot the training and validation accuracy over epochs and analyze\n",
        "overfitting or underfitting."
      ],
      "metadata": {
        "id": "WAEnRW08gI2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_test = X_train/255.0, X_test/255.0\n",
        "y_train, y_test = to_categorical(y_train,10), to_categorical(y_test,10)\n",
        "\n",
        "# Inception block\n",
        "def inception_block(x):\n",
        "    p1 = Conv2D(32, (1,1), activation='relu', padding='same')(x)\n",
        "    p2 = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
        "    p3 = Conv2D(32, (5,5), activation='relu', padding='same')(x)\n",
        "    p4 = MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
        "    return concatenate([p1, p2, p3, p4])\n",
        "\n",
        "# Model\n",
        "inputs = Input(shape=(32,32,3))\n",
        "x = inception_block(inputs)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "42n2Sm0GhNct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You are working in a healthcare AI startup. Your team is tasked with\n",
        "developing a system that automatically classifies medical X-ray images into normal,\n",
        "pneumonia, and COVID-19. Due to limited labeled data, what approach would you\n",
        "suggest using among CNN architectures discussed (e.g., transfer learning with ResNet\n",
        "or Inception variants)? Justify your approach and outline a deployment strategy for\n",
        "production use"
      ],
      "metadata": {
        "id": "_FxMJ1cmgMq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model Training (Transfer Learning – ResNet50)\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train = datagen.flow_from_directory(\n",
        "    \"dataset\", target_size=(224,224),\n",
        "    class_mode=\"categorical\", subset=\"training\")\n",
        "\n",
        "val = datagen.flow_from_directory(\n",
        "    \"dataset\", target_size=(224,224),\n",
        "    class_mode=\"categorical\", subset=\"validation\")\n",
        "\n",
        "base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base.output)\n",
        "out = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(base.input, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(train, validation_data=val, epochs=5)\n",
        "\n",
        "model.save(\"xray_model.h5\")\n"
      ],
      "metadata": {
        "id": "bV5xqioFg4Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deployment\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "import tensorflow as tf, numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "app = FastAPI()\n",
        "model = tf.keras.models.load_model(\"xray_model.h5\")\n",
        "classes = [\"Normal\", \"Pneumonia\", \"COVID\"]\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    img = Image.open(io.BytesIO(await file.read())).resize((224,224))\n",
        "    img = np.expand_dims(np.array(img)/255, axis=0)\n",
        "    pred = model.predict(img)\n",
        "    return {\"class\": classes[np.argmax(pred)]}\n"
      ],
      "metadata": {
        "id": "y7_ubPBEg6ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pZFozkk8g6JG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpfHvXakfqtm"
      },
      "outputs": [],
      "source": []
    }
  ]
}